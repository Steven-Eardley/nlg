\documentclass[a4paper,11pt,oneside]{article}

\begin{document}

\title{NLG Assignment 2}
\author{Steven Eardley s0934142}
%\maketitle

\section{Question 1.1}
The content plan contains the information that there should be three comparisons between the subjects, along with the corresponding items; the text plans 'flesh out' these outlines, with different presentations of the information. The first interleaves the sets of properties, switching subjects. The second groups the properties for each subject, while the third swaps the subjects around: Giovanni's first, Ti Ammo second. The text plan adds a structure to the content plan's definition of what should be contained in the text, but they all contain the same basic information, since they are based on the same content plan.

\section{Question 1.2}
No, the rankings do not appear correct. The model tends to prefer shorter sentences, meaning those in simple language which to me sound stilted are promoted to the top of the list. In addition, the top ranked sentence has a problem with adjective order: it says \emph[Italian mediocre] rather than the preferred \emph[mediocre Italian]. Finally, in the top ranked sentences only decor is mentioned, not quality of food, so these sentences don't contain as much information as later ones. These shortcomings may be due to the model being used out of domain - a newswire trained model will have been trained on texts in which brevity is valued, whereas here we wish to be more discriptive.

The top ranked sentence is:
\begin{verbatim}
Giovanni's is a good Italian restaurant, which has plain decor. 
Ti Amo is an Italian mediocre restaurant, which has tacky decor. 
\end{verbatim}

In the MATCH system, a decor appears at the bottom of the list of objectives, whereas food quality is found at the top. We'd prefer this system to also emphasise this information.

\section{Question 1.3}
Yes, there is some improvement, because the ranking is performed with a standard very specific to the task. The sentences at the top of the list with incorrect adjective order have gone, only one instance exists far down the list, plus all sentences contain information on food as well as decor, because all of these examples were removed from the corpus.  Another behaviour I attempted to discourage by removal from the corpus was the use of the same comparison phrase repeatedly - it didn't read very well when 'on the other hand' is used twice, for example:

\begin{verbatim}
    Giovanni's and Ti Amo are Italian restaurants. Ti Amo serves mediocre food. Giovanni's, 
    on the other hand, serves good food. Ti Amo has tacky decor. Giovanni's, on the other hand, has plain decor.
\end{verbatim}

Using the second language model did not affect this, however - there were still plenty of examples generated showing this behaviour, including the top two suggestions. This is a restriction with the model: there is no way using n-grams to perform long-reaching word preferences, since they only look at local frequency counts.

It is also clear that the shorter sentences are still preferred, at the cost of some sentence fluency.

\section{Question 1.4}
The web corpus trained language model does not provide much of an improvement over the WSJ language model, and the problem of repetition is still present. This problem and the issue with preferring shorter strings are unlikely to go away, as stated earlier. Interestingly, when this corpus is used in 50/50, 20/80 or 80/20 conjunction with the WSJ corpus, the results are the same as using the WSJ alone, with the same problem with missing information - only decor is mentioned, not food. For this reason it seems the \verb+restaurants-2+ language model is less useful than its predecessor.

Using only the web sourced model gives slightly better rankings than the WSJ alone - the adjective order is correct in the top ranked one:

\begin{verbatim}
Ti Amo is a mediocre Italian restaurant, which has tacky decor.
Giovanni's is a good Italian restaurant, which has plain decor.
\end{verbatim}

Like the WSJ, we have a loss of information. Using the two restaurant corpora together weighted 50/50 produce results similar to our good results from \verb+restaurants-1+ and the WSJ corpora. This seems to reinforce that \verb+restaurants-1+ is the best we have produced for the moment.

\section{Question 1.5}

Using the \verb+restaurants-3+ language model 50/50 with WSJ produces results indistinguishable from the smaller web corpus. The same errors are present, and the shorter strings which only discuss decor are preferred, once again. It seems there is little benefit to be found by adding more data which is in the same vein as previous useless data. When discarding the WSJ language model the results from \verb+restaurants+ alone look quite similar to the WSJ, but without the adjective order errors in the top ranked few.

The best results so far are found by using all three restaurant models, with comparable weights (34/33/33 respectively since they must sum to 100). The top ranked phrase:

\begin{verbatim}
Ti Amo and Giovanni's are Italian restaurants. Ti Amo serves mediocre food but Giovanni's serves good food. 
Ti Amo has tacky decor but Giovanni's has plain decor. 
\end{verbatim}

This is quite good because it keeps the subjects in the same order each time - it first addresses Ti Amo, then Giovanni's. It groups the similarities in the first sentence then contrasts those that are different. Although the word 'but' is used twice to contrast both properties in the text, it still reads well, and is not as noticeable as using the long phrase \emph{on the other hand}.

\section{Question 1.6}

Each language modeal was tested individually, then with different combinations, followed by different weights:
    
\begin{tabular}{ | c | c | c | c | }
  \hline                        
  Run no. & WSJ & r-1 & r-3 \\ \hline
  1 & 100 & 0 & 0 \\
  2 & 0 & 100 & 0 \\
  3 & 0 & 0 & 100 \\
  4 & 50 & 50 & 0 \\
  5 & 50 & 0 & 50 \\
  6 & 0 & 50 & 50 \\
  7 & 0 & 80 & 20 \\
  8 & 0 & 20 & 80 \\
  9 & 33 & 34 & 33 \\
  \hline  
\end{tabular}

The results were all very similar. Using the WSJ LM alone once again led to adjectives being incorrectly ordered near the top (although not the top ranked one). Using the \verb+restaurant-3+ language model did improve on this. The \verb+restaurant-1+ model in this case failed to produce ranks - each sentence was given 0. This is perhaps because it is too specific to the first task: producing comparison strings. Pairing it 50/50 with the WSJ gave the worst output, with errors in the top result. All other blends, on the other hand, produced equivalent results with acceptable outcomes. 

\section{Quesion 1.7}
The probablilities for longer sentences are diminished because the overall sentence production probability is a product of the n-gram frequency probabilities. Since all probabilities are always less than one, the overall probability will always decrease with length as more words are added and their probablities multiplied on. A solution to this is to apply a weight vector to counteract this effect: giving larger weights for each word added. This should be designed to counteract the loss of probability and not to give a preference for vastly long sentences.

\section{Quesion 1.8}
These phrases show the adjective ordering phenomenon as mentioned (many times) above. It shows those I have termed undesirable are found to have lower counts from Google. Using these frequencies, the results could be re-ranked according to how often the contained word orderings are used on the Web. For example, for a set of adjective permutations each could be searched with Google, and the results counts stored. Each sentence in which the permutation exists can be multiplied by a weight: the frequency divided by the sum of frequencies across all orderings. One would likely find an improvement over the current systems in such a case.

\section{Quesion 2.1}
\verb+nuc+ = nucleus \verb+sat+ = satelite

Text 1:
“Smalltown” and “Pandas” are the best shows for you. “Smalltown” opens soon, while “Pandas” opens later, and “Smalltown and “Pandas” are from very strong companies. “Smalltown is a teen drama while “Pandas” is a comedy-thriller.
\begin{verbatim}
Items:
        Smalltown, Pandas

Relations:
        conjunction ( nuc: 1, nuc: 2 ), elaboration ( nuc: 1, sat: 3 ), elaboration ( nuc: 2, sat: 6 ),
        contrast ( nuc: 3, nuc: 6 ), elaboration ( nuc: 1, sat: 4 ), elaboration ( nuc: 2, sat: 7 ),
        elaboration ( nuc: 1, sat: 5 ), elaboration ( nuc: 2, sat: 8 ), contrast ( nuc: 5, nuc: 8 )
        
Content:
        1. assert ( reccomendation ( Smalltown )
        2. assert ( reccomendation ( Pandas )
        3. assert ( has-attribute ( Smalltown, opens ( soon ) ) )
        4. assert ( has-attribute ( Smalltown, company ( strong ) ) )
        5. assert ( has-attribute ( Smalltown, type ( teen-drama ) ) )
        6. assert ( has-attribute ( Pandas, opens ( later ) ) )
        7. assert ( has-attribute ( Pandas, company ( strong ) ) )
        8. assert ( has-attribute ( Pandas, type ( comedy-thriller ) ) )
\end{verbatim}

Text 2:

“Smalltown” and Pandas” are the best shows for you. “Smalltown”, which is a teen drama, opens soon, and is from a strong company. “Pandas”, which is a comedy-thriller, is from a strong company, and opens later.
\begin{verbatim}
Items:
        Smalltown, Pandas

Relations:
        conjunction ( nuc: 1, nuc: 2 ), elaboration ( nuc: 1, sat: 5 ), elaboration ( nuc: 1, sat: 3 ),
        elaboration ( nuc: 1, sat: 4 ), elaboration ( nuc: 2, sat: 8 ), elaboration ( nuc: 1, sat: 7 ),
        elaboration ( nuc: 2, sat: 6 ), contrast ( nuc: 1, nuc: 2 )
        
Content:
        1. assert ( reccomendation ( Smalltown )
        2. assert ( reccomendation ( Pandas )
        3. assert ( has-attribute ( Smalltown, opens ( soon ) ) )
        4. assert ( has-attribute ( Smalltown, company ( strong ) ) )
        5. assert ( has-attribute ( Smalltown, type ( teen-drama ) ) )
        6. assert ( has-attribute ( Pandas, opens ( later ) ) )
        7. assert ( has-attribute ( Pandas, company ( strong ) ) )
        8. assert ( has-attribute ( Pandas, type ( comedy-thriller ) ) )

\end{verbatim}

The first text may be preferred because it does a better job of grouping the shared information, namely that they are 'from a strong company'. The following section also better serves as a justification of the assertion that those two shows are the best, rather than simply describing the shows individually.

\section{Quesion 2.2}
User X seems to prefer short sentences with little information in each, while user Y enjoys long sentences and commas to separate topics. To satisfy them both, don't go to either extreme, rather generate sentences of medium length with only one or two topics and commas.

\section{Quesion 2.3}
My attribute list, in order of importance:
\begin{enumerate}
\item Genre
\item Show's critic score
\item Social network friends going
\item Ticket price
\item Time of performance
\item Proximity to user
\end{enumerate}

Within a real-time system a user (say, someone with limited mobility) may require a different weighting to these preferences. In such a case, proximity to the user and time may feature highly compared to ticket price or the critic score, in order to assure that they can reach it in time. Perhaps a socialite may place having their Facebook friends going to the same show at the top of the list, or even give it a 50\% ranking with the critic score (after all, they'll want to go to the \emph{good} things their friends are at) and discard the remaining options.

MATCH's questionnaire method to assign weights (asking 'what would be the first thing you change'?') would be a good method for choosing weights for the attributes. It may also be possible for a more direct approach which lets the user have full control - presenting an interactive list where the user can move their preference to the top. An alternative and automatic method may be for the program to guess the weights and predict the outcome for a set of possible choices, then adjust the model weights according to the chosen option. This rather depends if the user is willing to put up with a few poor choices while the system is experimenting. This system would be improved by adding user ratings once the recommendation has been visited.

\section{Quesion 2.4}
If a user asks the system "Show me Italian restaurants I haven't visited this month" it would be beneficial for an application to only show a filtered set of results based on the user's history. A system without any user information would always recommend the same items for each query. Also in the example above, our less-mobile user may prefer to only see results within a shorter distance, and walking directions from the standard application may be difficult to follow.

A useful form of user allignment may is the detail used in text - some people may prefer lots of information and detailed assessment, whereas others may prefer a snappy soundbite to make up their mind. Checking how often a user uses a 'show more' button would allow a system to present shorter or longer reviews to the user. A non-alligned system would retain the same format for each review.
\end{document}
